{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# 2-Zero-Shot-Mutation-Variant-Clinvar-Alphamissense\n",
    "\n",
    "ClinVar variants pre-processed similar to AlphaMissense [1].\n",
    "\n",
    "## Dataset Information\n",
    "- **Dataset**: ClinVar Alphamissense\n",
    "- **Path**: `/data/validation/processed/alphamissense_clinvar_processed.csv`\n",
    "- **Task**: Zero-shot mutation effect prediction\n",
    "- **Models**: Pretrained Encodon models (80M, 600M, 1B)\n",
    "- **Evaluation**: Binary classification Benign vs Pathogenic variants using ROC-AUC and PR-AUC metrics\n",
    "\n",
    "[1] Cheng, Jun, et al. \"Accurate proteome-wide missense variant effect prediction with AlphaMissense.\" Science 381.6664 (2023): eadg7492."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import polars as pl\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional, Any\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import pickle\n",
    "import json\n",
    "from datetime import datetime\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Machine learning libraries\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Add project paths\n",
    "sys.path.append('..')\n",
    "\n",
    "# Import Encodon-specific modules\n",
    "from src.inference.encodon import EncodonInference\n",
    "from src.inference.task_types import TaskTypes\n",
    "from src.tokenizer import Tokenizer\n",
    "from src.data.metadata import MetadataFields, MetadataConstants\n",
    "from src.data.mutation_dataset import MutationDataset, collate_fn\n",
    "from src.data.preprocess.mutation_pred import mlm_process_item\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU device: {torch.cuda.get_device_name()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## 2. Load Encodon Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_encodon_inference_model(checkpoint_path: str, device: str = \"cuda\") -> EncodonInference:\n",
    "    \"\"\"\n",
    "    Load pretrained Encodon model using the inference wrapper.\n",
    "    \n",
    "    Args:\n",
    "        checkpoint_path: Path to the pretrained checkpoint\n",
    "        device: Device to load model on ('cuda' or 'cpu')\n",
    "        \n",
    "    Returns:\n",
    "        EncodonInference object ready for mutation prediction\n",
    "    \"\"\"\n",
    "    print(f\"Loading Encodon model from: {checkpoint_path}\")\n",
    "    \n",
    "    # Create inference wrapper\n",
    "    inference_model = EncodonInference(\n",
    "        model_path=checkpoint_path,\n",
    "        task_type=TaskTypes.MUTATION_PREDICTION\n",
    "    )\n",
    "    \n",
    "    # Configure the model (loads checkpoint and tokenizer)\n",
    "    inference_model.configure_model()\n",
    "    inference_model.eval()\n",
    "    \n",
    "    print(f\"‚úÖ Model loaded successfully on {device}\")\n",
    "    print(f\"Model parameters: {sum(p.numel() for p in inference_model.model.parameters()):,}\")\n",
    "    print(f\"Tokenizer vocabulary size: {inference_model.tokenizer.vocab_size}\")\n",
    "    \n",
    "    return inference_model\n",
    "\n",
    "\n",
    "# Define checkpoint paths to try (update these to your actual paths)\n",
    "# Define checkpoint paths to try (update these to your actual paths)\n",
    "ckpt_path = \"./\"\n",
    "checkpoint_paths = {\n",
    "    \"80M\": f\"{ckpt_path}/NV-CodonFM-Encodon-80M-v1/NV-CodonFM-Encodon-80M-v1.safetensors\",\n",
    "    \"600m\": f\"{ckpt_path}/NV-CodonFM-Encodon-600M-v1/NV-CodonFM-Encodon-600M-v1.safetensors\",\n",
    "    \"1B\": f\"{ckpt_path}/NV-CodonFM-Encodon-1B-v1/NV-CodonFM-Encodon-1B-v1.safetensors\",\n",
    "    \"1B_cdwt\": f\"{ckpt_path}/NV-CodonFM-Encodon-Cdwt-1B-v1/NV-CodonFM-Encodon-Cdwt-1B-v1.safetensors\"\n",
    "}\n",
    "\n",
    "\n",
    "model_loaded = False\n",
    "encodon_models = {}\n",
    "\n",
    "for size, checkpoint_path in checkpoint_paths.items():\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        try:\n",
    "            device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "            model = load_encodon_inference_model(checkpoint_path, device=device)\n",
    "            \n",
    "            # Extract model name from path\n",
    "            model_name = os.path.basename(os.path.dirname(os.path.dirname(checkpoint_path)))\n",
    "            display_name = f\"EnCodon ({size})\"\n",
    "            \n",
    "            encodon_models[display_name] = {\n",
    "                'model': model,\n",
    "                'path': checkpoint_path,\n",
    "                'device': device\n",
    "            }\n",
    "            print(f\"‚úÖ Successfully loaded {display_name} from: {checkpoint_path}\")\n",
    "            model_loaded = True\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to load from {checkpoint_path}: {e}\")\n",
    "            continue\n",
    "\n",
    "if not model_loaded:\n",
    "    print(\"‚ùå Could not load any Encodon model from the specified paths.\")\n",
    "    print(\"Please ensure a checkpoint exists or update the checkpoint_paths list.\")\n",
    "else:\n",
    "    print(f\"\\n‚úÖ Loaded {len(encodon_models)} models: {list(encodon_models.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## 3. Define Plotting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_size_key(model):\n",
    "    \"\"\"Helper to determine model size from its name.\"\"\"\n",
    "    name = model.lower()\n",
    "    if '80m' in name:\n",
    "        return (1, '80M')\n",
    "    elif '600m' in name:\n",
    "        return (3, '600M')\n",
    "    elif '1b' in name:\n",
    "        return (4, '1B')\n",
    "    else:\n",
    "        return (99, 'Unknown')\n",
    "\n",
    "\n",
    "def _assign_bar_colors(plot_data):\n",
    "    \"\"\"Assign unique colors to each bar based on model size (matching generate_results.py).\"\"\"\n",
    "    # Colors for EnCodon models (matching the provided figure)\n",
    "    encodon_colors = {\n",
    "        '80M': (0.0, 0.4, 0.8),      # Blue\n",
    "        '600M': (1.0, 0.5, 0.0),     # Orange\n",
    "        '1B': (0.0, 0.7, 0.0)        # Green\n",
    "    }\n",
    "    \n",
    "    colors = []\n",
    "    for i, (model_name, auc, size_str, model_type) in enumerate(plot_data):\n",
    "        if model_type == 'encodon':\n",
    "            color = encodon_colors.get(size_str, (0.5, 0.5, 0.5))\n",
    "        else:\n",
    "            color = (0.5, 0.5, 0.5)\n",
    "        colors.append(color)\n",
    "    return colors\n",
    "\n",
    "\n",
    "def calculate_mutation_metrics(df, model_columns):\n",
    "    \"\"\"Calculate ROC-AUC and PR-AUC metrics for mutation models.\"\"\"\n",
    "    metrics = {}\n",
    "    \n",
    "    for model_name, col in model_columns.items():\n",
    "        predictions = df[col]\n",
    "        true_labels = df['pathogenicity_label']\n",
    "        \n",
    "        # ROC-AUC\n",
    "        fpr, tpr, _ = roc_curve(true_labels, predictions)\n",
    "        roc_auc_value = auc(fpr, tpr)\n",
    "        \n",
    "        # PR-AUC\n",
    "        precision, recall, _ = precision_recall_curve(true_labels, predictions)\n",
    "        pr_auc_value = auc(recall, precision)\n",
    "        \n",
    "        metrics[model_name] = {\n",
    "            'roc_auc': roc_auc_value,\n",
    "            'pr_auc': pr_auc_value,\n",
    "            'fpr': fpr,\n",
    "            'tpr': tpr,\n",
    "            'precision': precision,\n",
    "            'recall': recall\n",
    "        }\n",
    "    \n",
    "    baseline_pr = np.sum(df['pathogenicity_label']) / len(df)\n",
    "    metrics[\"Baseline\"] = {\n",
    "        'roc_auc': 0.5,\n",
    "        'pr_auc': baseline_pr\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "\n",
    "def plot_results(metrics, dataset_name, save_prefix):\n",
    "    \"\"\"Create comprehensive plots for the results.\"\"\"\n",
    "    # Set up plot style\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    \n",
    "    # Create figure with subplots\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(24, 8))\n",
    "    fig.suptitle(f'{dataset_name} - Encodon Model Performance', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Generate colors for models\n",
    "    models_to_plot = [m for m in metrics if m != \"Baseline\"]\n",
    "    palette = sns.color_palette(\"tab10\", len(models_to_plot))\n",
    "    model_colors = dict(zip(models_to_plot, palette))\n",
    "    \n",
    "    # ROC curve\n",
    "    ax1 = axes[0]\n",
    "    for model in models_to_plot:\n",
    "        model_metrics = metrics[model]\n",
    "        ax1.plot(\n",
    "            model_metrics['fpr'], \n",
    "            model_metrics['tpr'], \n",
    "            label=f\"{model} (AUC = {model_metrics['roc_auc']:.3f})\",\n",
    "            color=model_colors.get(model, \"black\"),\n",
    "            linewidth=2\n",
    "        )\n",
    "    \n",
    "    ax1.plot([0, 1], [0, 1], linestyle=\"--\", color=\"red\", \n",
    "             label=\"Random (AUC = 0.500)\", linewidth=1.5)\n",
    "    ax1.set_xlabel(\"False Positive Rate\", fontsize=12)\n",
    "    ax1.set_ylabel(\"True Positive Rate\", fontsize=12)\n",
    "    ax1.set_title(f\"ROC Curves\", fontsize=14, fontweight='bold')\n",
    "    ax1.grid(True, linestyle='--', alpha=0.7)\n",
    "    ax1.legend(loc=\"lower right\", frameon=True, framealpha=0.9, fontsize=10)\n",
    "    \n",
    "    # PR curve\n",
    "    ax2 = axes[1]\n",
    "    for model in models_to_plot:\n",
    "        model_metrics = metrics[model]\n",
    "        ax2.plot(\n",
    "            model_metrics['recall'], \n",
    "            model_metrics['precision'], \n",
    "            label=f\"{model} (AUC = {model_metrics['pr_auc']:.3f})\",\n",
    "            color=model_colors.get(model, \"black\"),\n",
    "            linewidth=2\n",
    "        )\n",
    "    \n",
    "    baseline_pr = metrics[\"Baseline\"][\"pr_auc\"]\n",
    "    ax2.hlines(baseline_pr, 0, 1, colors='red', linestyles='--', \n",
    "               label=f'Baseline (AUC = {baseline_pr:.3f})', linewidth=1.5)\n",
    "    ax2.set_xlabel(\"Recall\", fontsize=12)\n",
    "    ax2.set_ylabel(\"Precision\", fontsize=12)\n",
    "    ax2.set_title(f\"Precision-Recall Curves\", fontsize=14, fontweight='bold')\n",
    "    ax2.grid(True, linestyle='--', alpha=0.7)\n",
    "    ax2.legend(loc=\"lower left\", frameon=True, framealpha=0.9, fontsize=10)\n",
    "    \n",
    "    # Bar plot\n",
    "    ax3 = axes[2]\n",
    "    models = [m for m in metrics if m != \"Baseline\"]\n",
    "    \n",
    "    # Prepare plot data\n",
    "    plot_data = []\n",
    "    for m in models:\n",
    "        size_str = get_size_key(m)[1]\n",
    "        plot_data.append((m, metrics[m]['roc_auc'], size_str, 'encodon'))\n",
    "    \n",
    "    # Sort by size then by performance\n",
    "    plot_data.sort(key=lambda x: (get_size_key(x[0])[0], -x[1]))\n",
    "    colors = _assign_bar_colors(plot_data)\n",
    "    \n",
    "    x_positions = np.arange(len(plot_data))\n",
    "    aucs = [auc for _, auc, _, _ in plot_data]\n",
    "    bars = ax3.bar(x=x_positions, height=aucs, color=colors, \n",
    "                   edgecolor='black', linewidth=1.0, alpha=1.0)\n",
    "    \n",
    "    # Annotate bars\n",
    "    for i, (model_name, auc_val, _, _) in enumerate(plot_data):\n",
    "        ax3.text(i, bars[i].get_height() + 0.02, f\"{auc_val:.3f}\", \n",
    "                ha='center', va='bottom', fontsize=9, color='black')\n",
    "    \n",
    "    ax3.set_xticks(x_positions)\n",
    "    ax3.set_xticklabels([model_name for model_name, _, _, _ in plot_data], \n",
    "                        rotation=30, ha='right', fontsize=10)\n",
    "    ax3.set_title(f\"Model Performance Comparison\", fontsize=14, fontweight='bold')\n",
    "    ax3.set_xlabel('Model', fontsize=12)\n",
    "    ax3.set_ylabel('AUROC', fontsize=12)\n",
    "    ax3.set_ylim(0, max(aucs) + 0.1 if aucs else 1.0)\n",
    "    ax3.grid(True, linestyle='-', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{save_prefix}_results.png\", dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "print(\"‚úÖ Plotting functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## 4. Load ClinVar Alphamissense Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ClinVar Alphamissense dataset\n",
    "DATASET_CONFIG = {\n",
    "    'key': 'clinvar_alphamissense',\n",
    "    'name': 'ClinVar Alphamissense',\n",
    "    'data_path': '/data/validation/processed/alphamissense_clinvar_processed.csv',\n",
    "    'description': 'ClinVar variants processed with AlphaMissense-style filtering for consistent evaluation.'\n",
    "}\n",
    "\n",
    "def load_dataset(config):\n",
    "    \"\"\"Load and inspect the ClinVar Alphamissense dataset.\"\"\"\n",
    "    print(f\"Loading {config['name']} dataset...\")\n",
    "    print(f\"Path: {config['data_path']}\")\n",
    "    \n",
    "    if not os.path.exists(config['data_path']):\n",
    "        print(f\"‚ùå Dataset not found: {config['data_path']}\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Load data using polars then convert to pandas\n",
    "        data = pl.read_csv(config['data_path'], ignore_errors=True).to_pandas()\n",
    "        print(f\"‚úÖ Loaded {len(data)} variants\")\n",
    "        print(f\"Shape: {data.shape}\")\n",
    "        print(f\"Columns: {list(data.columns)}\")\n",
    "        \n",
    "        # Check for required columns\n",
    "        required_cols = ['id', 'ref_seq', 'ref_codon', 'alt_codon', 'codon_position']\n",
    "        missing_cols = [col for col in required_cols if col not in data.columns]\n",
    "        \n",
    "        if missing_cols:\n",
    "            print(f\"‚ö†Ô∏è Missing columns: {missing_cols}\")\n",
    "        else:\n",
    "            print(\"‚úÖ All required columns present\")\n",
    "        \n",
    "        # Handle labels based on dataset type\n",
    "        data['pathogenicity_label'] = data['label']\n",
    "        \n",
    "        # Show sample data\n",
    "        display_cols = [col for col in ['id', 'ref_codon', 'alt_codon', 'codon_position'] if col in data.columns]\n",
    "        display_cols.append('pathogenicity_label')\n",
    "        \n",
    "        print(f\"\\nSample data:\")\n",
    "        print(data[display_cols].head(3))\n",
    "        \n",
    "        return data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to load dataset: {e}\")\n",
    "        return None\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset(DATASET_CONFIG)\n",
    "print(f\"\\nüìä Dataset loaded: {dataset is not None}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## 5. Run Mutation Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_mutation_predictions(models, data):\n",
    "    \"\"\"Run mutation predictions for ClinVar Alphamissense dataset.\"\"\"\n",
    "    if data is None or not models:\n",
    "        print(\"‚ùå No data or models available\")\n",
    "        return {}\n",
    "    \n",
    "    print(f\"\\n=== RUNNING MUTATION PREDICTIONS FOR CLINVAR ALPHAMISSENSE ===\")\n",
    "    \n",
    "    data_subset = data.copy()\n",
    "    all_predictions = {}\n",
    "    \n",
    "    for model_name, model_info in models.items():\n",
    "        print(f\"\\n--- Processing {model_name} ---\")\n",
    "        \n",
    "        # Create temporary CSV file\n",
    "        temp_csv_path = f\"/tmp/clinvar_alphamissense_{model_name.replace(' ', '_')}_temp.csv\"\n",
    "        data_subset.to_csv(temp_csv_path, index=False)\n",
    "        \n",
    "        try:\n",
    "            # Create MutationDataset\n",
    "            mutation_dataset = MutationDataset(\n",
    "                data_path=temp_csv_path,\n",
    "                tokenizer=model_info['model'].tokenizer,\n",
    "                process_item=mlm_process_item,\n",
    "                context_length=2048,\n",
    "                task=\"mlm\",\n",
    "                extract_seq=True,\n",
    "                train_val_test_ratio=None\n",
    "            )\n",
    "            \n",
    "            # Create DataLoader\n",
    "            dataloader = torch.utils.data.DataLoader(\n",
    "                mutation_dataset,\n",
    "                batch_size=32,\n",
    "                shuffle=False,\n",
    "                collate_fn=collate_fn,\n",
    "                num_workers=0\n",
    "            )\n",
    "            \n",
    "            # Run predictions\n",
    "            all_ids = []\n",
    "            all_likelihood_ratios = []\n",
    "            \n",
    "            model_info['model'].eval()\n",
    "            model_info['model'].to(model_info['device'])\n",
    "            with torch.no_grad():\n",
    "                for batch in tqdm(dataloader, desc=f\"{model_name} predictions\"):\n",
    "                    # Move batch to device\n",
    "                    for key in batch:\n",
    "                        if isinstance(batch[key], torch.Tensor):\n",
    "                            batch[key] = batch[key].to(model_info['device'])\n",
    "                    \n",
    "                    # Get predictions\n",
    "                    output = model_info['model'].predict_mutation(batch, ids=batch[MetadataFields.ID])\n",
    "                    \n",
    "                    all_ids.extend(output.ids)\n",
    "                    all_likelihood_ratios.extend(output.likelihood_ratios)\n",
    "            \n",
    "            all_predictions[model_name] = {\n",
    "                'ids': np.array(all_ids),\n",
    "                'likelihood_ratios': np.array(all_likelihood_ratios)\n",
    "            }\n",
    "            \n",
    "            print(f\"‚úÖ Completed {len(all_ids)} predictions\")\n",
    "            print(f\"Likelihood ratio range: [{np.min(all_likelihood_ratios):.3f}, {np.max(all_likelihood_ratios):.3f}]\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed predictions for {model_name}: {e}\")\n",
    "            continue\n",
    "        finally:\n",
    "            # Clean up temporary file\n",
    "            if os.path.exists(temp_csv_path):\n",
    "                os.remove(temp_csv_path)\n",
    "            \n",
    "            # Offload model from GPU to free memory\n",
    "            if 'model' in model_info and hasattr(model_info['model'], 'cpu'):\n",
    "                model_info['model'].cpu()\n",
    "                print(f\"üîÑ Offloaded {model_name} from GPU\")\n",
    "            \n",
    "            # Clear GPU cache\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "                print(f\"üßπ Cleared GPU cache after {model_name}\")\n",
    "    \n",
    "    return all_predictions\n",
    "\n",
    "# Run predictions if models and dataset are available\n",
    "if 'encodon_models' in locals() and 'dataset' in locals() and dataset is not None:\n",
    "    predictions = run_mutation_predictions(encodon_models, dataset)\n",
    "    print(f\"\\n‚úÖ Predictions completed for {len(predictions)} models\")\n",
    "else:\n",
    "    print(\"‚ùå Cannot run predictions - missing models or dataset\")\n",
    "    predictions = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## 6. Evaluate Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_and_plot_clinvar_alphamissense_results(predictions, data):\n",
    "    \"\"\"Evaluate and plot results for ClinVar Alphamissense.\"\"\"\n",
    "    if not predictions or data is None:\n",
    "        print(\"‚ùå No predictions or data available\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\n=== EVALUATING CLINVAR ALPHAMISSENSE RESULTS ===\")\n",
    "    \n",
    "    # Check if we have pathogenicity labels for ROC/PR analysis\n",
    "    if 'pathogenicity_label' not in data.columns:\n",
    "        print(f\"‚ö†Ô∏è No pathogenicity labels found - skipping ROC/PR analysis\")\n",
    "        return\n",
    "    \n",
    "    # Create evaluation dataframe\n",
    "    eval_df = data.copy()\n",
    "    model_columns = {}\n",
    "    \n",
    "    for model_name, pred_data in predictions.items():\n",
    "        # Create mapping from ID to likelihood ratio\n",
    "        id_to_lr = dict(zip(pred_data['ids'], pred_data['likelihood_ratios']))\n",
    "        \n",
    "        # Add predictions to dataframe\n",
    "        col_name = f\"likelihood_ratios_{model_name}\"\n",
    "        eval_df[col_name] = eval_df['id'].map(id_to_lr)\n",
    "        model_columns[model_name] = col_name\n",
    "        \n",
    "        # Report coverage\n",
    "        coverage = eval_df[col_name].notna().sum()\n",
    "        print(f\"{model_name}: {coverage}/{len(eval_df)} variants ({coverage/len(eval_df)*100:.1f}%)\")\n",
    "    \n",
    "    # Filter to complete cases\n",
    "    mask = pd.Series(True, index=eval_df.index)\n",
    "    for col in model_columns.values():\n",
    "        mask &= ~eval_df[col].isna()\n",
    "    \n",
    "    eval_df_filtered = eval_df[mask]\n",
    "    print(f\"\\nEvaluation set: {len(eval_df_filtered)} variants with complete predictions\")\n",
    "    \n",
    "    if len(eval_df_filtered) < 10:\n",
    "        print(\"‚ö†Ô∏è Too few samples for reliable evaluation\")\n",
    "        return\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = calculate_mutation_metrics(eval_df_filtered, model_columns)\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\nüìä Performance Summary:\")\n",
    "    for model_name in model_columns.keys():\n",
    "        m = metrics[model_name]\n",
    "        print(f\"  {model_name}: ROC-AUC = {m['roc_auc']:.4f}, PR-AUC = {m['pr_auc']:.4f}\")\n",
    "    \n",
    "    # Create plots\n",
    "    plot_results(metrics, 'ClinVar Alphamissense', 'clinvar_alphamissense')\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Run evaluation\n",
    "if 'predictions' in locals() and 'dataset' in locals():\n",
    "    results = evaluate_and_plot_clinvar_alphamissense_results(predictions, dataset)\n",
    "else:\n",
    "    print(\"‚ùå No predictions or dataset available for evaluation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## 7. Save/Load Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and load functionality for ClinVar Alphamissense\n",
    "def save_clinvar_alphamissense_results(predictions, filename='clinvar_alphamissense_results.pkl'):\n",
    "    \"\"\"Save ClinVar Alphamissense prediction results.\"\"\"\n",
    "    results_to_save = {\n",
    "        'predictions': predictions,\n",
    "        'dataset_key': 'clinvar_alphamissense',\n",
    "        'dataset_name': 'ClinVar Alphamissense',\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'models': list(predictions.keys()) if predictions else []\n",
    "    }\n",
    "    \n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(results_to_save, f)\n",
    "    \n",
    "    print(f\"‚úÖ ClinVar Alphamissense results saved to {filename}\")\n",
    "    print(f\"   Models: {results_to_save['models']}\")\n",
    "    print(f\"   Timestamp: {results_to_save['timestamp']}\")\n",
    "\n",
    "def load_clinvar_alphamissense_results(filename='clinvar_alphamissense_results.pkl'):\n",
    "    \"\"\"Load ClinVar Alphamissense prediction results.\"\"\"\n",
    "    if not os.path.exists(filename):\n",
    "        print(f\"‚ùå Results file not found: {filename}\")\n",
    "        return {}\n",
    "    \n",
    "    with open(filename, 'rb') as f:\n",
    "        results = pickle.load(f)\n",
    "    \n",
    "    print(f\"‚úÖ ClinVar Alphamissense results loaded from {filename}\")\n",
    "    print(f\"   Models: {results.get('models', [])}\")\n",
    "    print(f\"   Timestamp: {results.get('timestamp', 'Unknown')}\")\n",
    "    \n",
    "    return results.get('predictions', {})\n",
    "\n",
    "# Save current results if available\n",
    "if 'predictions' in locals() and predictions:\n",
    "    save_clinvar_alphamissense_results(predictions)\n",
    "    print(f\"\\nüíæ ClinVar Alphamissense results saved!\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è No ClinVar Alphamissense results to save yet\")\n",
    "\n",
    "# Try to load existing results\n",
    "if os.path.exists('clinvar_alphamissense_results.pkl'):\n",
    "    saved_predictions = load_clinvar_alphamissense_results()\n",
    "    if saved_predictions and not locals().get('predictions'):\n",
    "        predictions = saved_predictions\n",
    "        print(f\"   Using saved results for analysis\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
