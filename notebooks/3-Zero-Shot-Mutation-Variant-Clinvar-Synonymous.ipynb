{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ca5a91d",
   "metadata": {},
   "source": [
    "# 3-Zero-Shot-Mutation-Variant-Clinvar-Synonymous\n",
    "\n",
    "Synonymous ClinVar variants evaluation to assesss models ability to distinguish between synonymous mutations that are pathogenic vs benign.\n",
    "\n",
    "## Dataset Information\n",
    "- **Dataset**: ClinVar Synonymous\n",
    "- **Path**: `/data/validation/processed/clinvar_synom.csv`\n",
    "- **Task**: Zero-shot mutation effect prediction\n",
    "- **Models**: Pretrained Encodon models (80M, 600M, 1B)\n",
    "- **Evaluation**: Mann-Whitney U test between healthy and disease patients (-log10p) significant test values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from scipy.stats import mannwhitneyu\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Add project paths\n",
    "sys.path.append('..')\n",
    "\n",
    "# Import Encodon-specific modules\n",
    "from src.data.metadata import MetadataFields\n",
    "from src.data.mutation_dataset import MutationDataset, collate_fn\n",
    "from src.data.preprocess.mutation_pred import mlm_process_item\n",
    "from src.inference.encodon import EncodonInference\n",
    "from src.inference.task_types import TaskTypes\n",
    "\n",
    "\n",
    "print(\"âœ… All libraries imported successfully!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU device: {torch.cuda.get_device_name()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration: Data paths and model checkpoints\n",
    "DATA_INPUT_PATH = '/data/validation/processed/clinvar_synom.csv'\n",
    "OUTPUT_DIR = '/data/validation/encodons_results/clinvar_synom'\n",
    "\n",
    "# Model checkpoints for inference\n",
    "\n",
    "ckpt_path = \"/data/validation/checkpoints/release_checkpoints/release_safetensors_files\"\n",
    "MODEL_CHECKPOINTS = {\n",
    "    \"80M\": f\"{ckpt_path}/NV-CodonFM-Encodon-80M-v1/NV-CodonFM-Encodon-80M-v1.safetensors\",\n",
    "    \"600m\": f\"{ckpt_path}/NV-CodonFM-Encodon-600M-v1/NV-CodonFM-Encodon-600M-v1.safetensors\",\n",
    "    \"1B\": f\"{ckpt_path}/NV-CodonFM-Encodon-1B-v1/NV-CodonFM-Encodon-1B-v1.safetensors\",\n",
    "    \"1B_cdwt\": f\"{ckpt_path}/NV-CodonFM-Encodon-Cdwt-1B-v1/NV-CodonFM-Encodon-Cdwt-1B-v1.safetensors\"\n",
    "}\n",
    "\n",
    "# Inference parameters\n",
    "BATCH_SIZE = 64\n",
    "NUM_WORKERS = 4\n",
    "CONTEXT_LENGTH = 2048"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "# Running inference\n",
    "\n",
    "This part can be skipped if the predictions are already in place"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fc0b93",
   "metadata": {},
   "source": [
    "### Load models checkpoints:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_encodon_inference_model(checkpoint_path: str, device: str = \"cuda\") -> EncodonInference:\n",
    "    \"\"\"\n",
    "    Load pretrained Encodon model using the inference wrapper.\n",
    "    \n",
    "    Args:\n",
    "        checkpoint_path: Path to the pretrained checkpoint\n",
    "        device: Device to load model on ('cuda' or 'cpu')\n",
    "        \n",
    "    Returns:\n",
    "        EncodonInference object ready for mutation prediction\n",
    "    \"\"\"\n",
    "    print(f\"Loading Encodon model from: {checkpoint_path}\")\n",
    "    \n",
    "    # Create inference wrapper\n",
    "    inference_model = EncodonInference(\n",
    "        model_path=checkpoint_path,\n",
    "        task_type=TaskTypes.MUTATION_PREDICTION\n",
    "    )\n",
    "    \n",
    "    # Configure the model (loads checkpoint and tokenizer)\n",
    "    inference_model.configure_model()\n",
    "    inference_model.eval()\n",
    "    \n",
    "    print(f\"âœ… Model loaded successfully on {device}\")\n",
    "    print(f\"Model parameters: {sum(p.numel() for p in inference_model.model.parameters()):,}\")\n",
    "    print(f\"Tokenizer vocabulary size: {inference_model.tokenizer.vocab_size}\")\n",
    "    \n",
    "    return inference_model\n",
    "\n",
    "\n",
    "model_loaded = False\n",
    "encodon_models = {}\n",
    "\n",
    "for size, checkpoint_path in MODEL_CHECKPOINTS.items():\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        try:\n",
    "            device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "            model = load_encodon_inference_model(checkpoint_path, device=device)\n",
    "            \n",
    "            # Extract model name from path\n",
    "            model_name = os.path.basename(os.path.dirname(os.path.dirname(checkpoint_path)))\n",
    "            display_name = f\"EnCodon ({size})\"\n",
    "            \n",
    "            encodon_models[display_name] = {\n",
    "                'model': model,\n",
    "                'path': checkpoint_path,\n",
    "                'device': device,\n",
    "                'original_name': size\n",
    "            }\n",
    "            print(f\"âœ… Successfully loaded {display_name} from: {checkpoint_path}\")\n",
    "            model_loaded = True\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to load from {checkpoint_path}: {e}\")\n",
    "            continue\n",
    "\n",
    "if not model_loaded:\n",
    "    print(\"âŒ Could not load any Encodon model from the specified paths.\")\n",
    "    print(\"Please ensure a checkpoint exists or update the checkpoint_paths list.\")\n",
    "else:\n",
    "    print(f\"\\nâœ… Loaded {len(encodon_models)} models: {list(encodon_models.keys())}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf87deb",
   "metadata": {},
   "source": [
    "### Load ClinVar Synonymous Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28774ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ClinVar Synonymous dataset\n",
    "DATASET_CONFIG = {\n",
    "    'key': 'clinvar_synom',\n",
    "    'name': 'ClinVar Synonymous',\n",
    "    'data_path': '/data/validation/processed/clinvar_synom.csv',\n",
    "}\n",
    "\n",
    "def load_dataset(config):\n",
    "    \"\"\"Load and inspect the ClinVar Synonymous dataset.\"\"\"\n",
    "    print(f\"Loading {config['name']} dataset...\")\n",
    "    print(f\"Path: {config['data_path']}\")\n",
    "    \n",
    "    if not os.path.exists(config['data_path']):\n",
    "        print(f\"âŒ Dataset not found: {config['data_path']}\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Load data using polars then convert to pandas\n",
    "        data = pl.read_csv(config['data_path'], ignore_errors=True).to_pandas()\n",
    "        print(f\"âœ… Loaded {len(data)} variants\")\n",
    "        print(f\"Shape: {data.shape}\")\n",
    "        print(f\"Columns: {list(data.columns)}\")\n",
    "        \n",
    "        # Check for required columns\n",
    "        required_cols = ['id', 'ref_seq', 'ref_codon', 'alt_codon', 'codon_position']\n",
    "        missing_cols = [col for col in required_cols if col not in data.columns]\n",
    "        \n",
    "        if missing_cols:\n",
    "            print(f\"âš ï¸ Missing columns: {missing_cols}\")\n",
    "        else:\n",
    "            print(\"âœ… All required columns present\")\n",
    "\n",
    "        # Show sample data\n",
    "        display_cols = [col for col in ['id', 'ref_codon', 'alt_codon', 'codon_position'] if col in data.columns]\n",
    "        display_cols.append('label')\n",
    "        \n",
    "        print(f\"\\nSample data:\")\n",
    "        print(data[display_cols].head(3))\n",
    "\n",
    "        # Set dataloader \n",
    "        \n",
    "        return data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Failed to load dataset: {e}\")\n",
    "        return None\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset(DATASET_CONFIG)\n",
    "print(f\"\\nðŸ“Š Dataset loaded: {dataset is not None}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d60d26",
   "metadata": {},
   "source": [
    "### Run mutation predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db53ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_mutation_predictions(models, data, batch_size=32):\n",
    "    \"\"\"Run mutation predictions for ClinVar Alphamissense dataset.\"\"\"\n",
    "    if data is None or not models:\n",
    "        print(\"âŒ No data or models available\")\n",
    "        return {}\n",
    "    \n",
    "    print(f\"\\n=== RUNNING MUTATION PREDICTIONS FOR CLINVAR SYNONYMOUS ===\")\n",
    "     # Create output directory\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "    data_subset = data.copy()\n",
    "    all_predictions = {}\n",
    "    \n",
    "    for model_name, model_info in models.items():\n",
    "        original_model_name = model_info.get('original_name', model_name)\n",
    "        print(f\"\\n--- Processing {model_name} ---\")\n",
    "        output_path = os.path.join(OUTPUT_DIR, f'preds_{original_model_name}.csv')\n",
    "        \n",
    "        # Create temporary CSV file\n",
    "        temp_csv_path = f\"/tmp/clinvar_synonymous_{original_model_name.replace(' ', '_')}_temp.csv\"\n",
    "        data_subset.to_csv(temp_csv_path, index=False)\n",
    "        \n",
    "        try:\n",
    "            # Create MutationDataset\n",
    "            mutation_dataset = MutationDataset(\n",
    "                data_path=temp_csv_path,\n",
    "                tokenizer=model_info['model'].tokenizer,\n",
    "                process_item=mlm_process_item,\n",
    "                context_length=2048,\n",
    "                task=\"mlm\",\n",
    "                extract_seq=True,\n",
    "                train_val_test_ratio=None\n",
    "            )\n",
    "            \n",
    "            # Create DataLoader\n",
    "            dataloader = DataLoader(\n",
    "                mutation_dataset,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=False,\n",
    "                collate_fn=collate_fn,\n",
    "                num_workers=0\n",
    "            )\n",
    "            \n",
    "            # Run predictions\n",
    "            all_ids = []\n",
    "            all_likelihood_ratios = []\n",
    "            \n",
    "            model_info['model'].eval()\n",
    "            model_info['model'].to(model_info['device'])\n",
    "            with torch.no_grad():\n",
    "                for batch in tqdm(dataloader, desc=f\"{model_name} predictions\"):\n",
    "                    # Move batch to device\n",
    "                    for key in batch:\n",
    "                        if isinstance(batch[key], torch.Tensor):\n",
    "                            batch[key] = batch[key].to(model_info['device'])\n",
    "                    \n",
    "                    # Get predictions\n",
    "                    output = model_info['model'].predict_mutation(batch, ids=batch[MetadataFields.ID])\n",
    "                    \n",
    "                    all_ids.extend(output.ids)\n",
    "                    all_likelihood_ratios.extend(output.likelihood_ratios)\n",
    "            \n",
    "            # Save predictions of current model\n",
    "            out_df = pl.DataFrame({\n",
    "                'id': np.array(all_ids),\n",
    "                original_model_name: np.array(all_likelihood_ratios)\n",
    "            })\n",
    "            out_df = out_df.with_columns(pl.col('id').cast(pl.UInt32))\n",
    "            out_df.write_csv(output_path)\n",
    "\n",
    "            print(f\"Predictions saved to {output_path}\") \n",
    "            print(f\"âœ… Completed {len(all_ids)} predictions\")\n",
    "            print(f\"Likelihood ratio range: [{np.min(all_likelihood_ratios):.3f}, {np.max(all_likelihood_ratios):.3f}]\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Failed predictions for {model_name}: {e}\")\n",
    "            continue\n",
    "        finally:\n",
    "            # Clean up temporary file\n",
    "            if os.path.exists(temp_csv_path):\n",
    "                os.remove(temp_csv_path)\n",
    "            \n",
    "            # Offload model from GPU to free memory\n",
    "            if 'model' in model_info and hasattr(model_info['model'], 'cpu'):\n",
    "                model_info['model'].cpu()\n",
    "                print(f\"ðŸ”„ Offloaded {model_name} from GPU\")\n",
    "            \n",
    "            # Clear GPU cache\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "                print(f\"ðŸ§¹ Cleared GPU cache after {model_name}\")\n",
    "    \n",
    "    return all_predictions\n",
    "\n",
    "# Run predictions if models and dataset are available\n",
    "if 'encodon_models' in locals() and 'dataset' in locals() and dataset is not None:\n",
    "    predictions = run_mutation_predictions(encodon_models, dataset)\n",
    "    print(f\"\\nâœ… Predictions completed for {len(predictions)} models\")\n",
    "else:\n",
    "    print(\"âŒ Cannot run predictions - missing models or dataset\")\n",
    "    predictions = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "# Scoring: Pathogenic vs Benign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset with predictions from inference section\n",
    "print(\"Loading dataset...\")\n",
    "dset = pl.read_csv(DATA_INPUT_PATH)\n",
    "print(f\"Dataset shape: {dset.shape}\")\n",
    "print(f\"Label distribution:\")\n",
    "print(dset['label'].value_counts())\n",
    "\n",
    "# Load predictions from inference paths saved in previous section\n",
    "print(\"\\nLoading predictions from inference outputs...\")\n",
    "for model_name in MODEL_CHECKPOINTS.keys():\n",
    "    pred_path = os.path.join(OUTPUT_DIR, f'preds_{model_name}.csv')\n",
    "    if os.path.exists(pred_path):\n",
    "        print(f\"  Loading {model_name} from {pred_path}\")\n",
    "        pred_df = pl.read_csv(pred_path)\n",
    "        dset = dset.join(pred_df, on='id', how='left')\n",
    "        print(f\"    Loaded {len(pred_df)} predictions\")\n",
    "    else:\n",
    "        print(f\"  Warning: Predictions for {model_name} not found at {pred_path}\")\n",
    "\n",
    "# Add pathogenicity label\n",
    "dset = dset.with_columns(\n",
    "    (pl.col('label').str.to_lowercase().str.contains('pathogenic').cast(pl.Int8)).alias('is_pathogenic')\n",
    ")\n",
    "\n",
    "print(f\"\\nFinal dataset shape: {dset.shape}\")\n",
    "print(f\"Columns with predictions: {[col for col in dset.columns if col in MODEL_CHECKPOINTS.keys()]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_cols = [col for col in dset.columns if col in MODEL_CHECKPOINTS.keys()]\n",
    "# Create separate plots for each model\n",
    "for model_name in preds_cols:\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "    for j, (in_splice, ax) in enumerate(zip([True, False], [ax1, ax2])):\n",
    "        # Filter data based on splice junction status\n",
    "        filtered_data = dset.filter(pl.col('in_splice_junction') == in_splice).to_pandas()\n",
    "        \n",
    "        # Separate pathogenic and benign data (only from filtered data)\n",
    "        pathogenic_data = filtered_data[filtered_data['is_pathogenic'] == 1][model_name].dropna()\n",
    "        benign_data = filtered_data[filtered_data['is_pathogenic'] == 0][model_name].dropna()\n",
    "        \n",
    "        # Calculate Mann-Whitney U test\n",
    "        p_value = None\n",
    "        if len(pathogenic_data) > 0 and len(benign_data) > 0:\n",
    "            _, p_value = mannwhitneyu(pathogenic_data, benign_data, alternative='two-sided')\n",
    "        \n",
    "        # Create histogram with custom labels\n",
    "        sns.histplot(\n",
    "            data=filtered_data,\n",
    "            x=model_name,\n",
    "            hue='is_pathogenic',\n",
    "            hue_order=[0, 1],\n",
    "            bins=50,\n",
    "            kde=True,\n",
    "            stat='proportion',\n",
    "            common_norm=False,\n",
    "            ax=ax\n",
    "        )\n",
    "        \n",
    "\n",
    "        # hue_order=[0, 1] means: 0=Benign (first), 1=Pathogenic (second)\n",
    "        legend_labels = [f'Benign (n={len(benign_data)})', f'Pathogenic (n={len(pathogenic_data)})']\n",
    "        legend = ax.get_legend()\n",
    "        if legend is not None:\n",
    "            for idx, text in enumerate(legend.get_texts()):\n",
    "                if idx < len(legend_labels):\n",
    "                    text.set_text(legend_labels[idx])\n",
    "        else:\n",
    "            # If no legend exists, create one manually\n",
    "            ax.legend(labels=legend_labels)\n",
    "        \n",
    "\n",
    "        splice_status = \"IN\" if in_splice else \"NOT in\"\n",
    "        title = f'Histogram of {model_name} by Pathogenicity ({splice_status} Splice Junction)'\n",
    "        if p_value is not None:\n",
    "            title += f'\\nMann-Whitney U p-value: {p_value:.2e}'\n",
    "        \n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel(f'{model_name} likelihood ratio')\n",
    "        ax.set_ylabel('Density')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dset.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = dset.filter(~pl.col('in_splice_junction')).to_pandas()\n",
    "temp['is_pathogenic'] = temp['is_pathogenic'].astype(bool)\n",
    "\n",
    "mwu_scores = []\n",
    "\n",
    "patho = temp.loc[temp['is_pathogenic']]\n",
    "non_patho = temp.loc[~temp['is_pathogenic']]\n",
    "for col in preds_cols + ['phylop', 'codon_freq_ratio']:\n",
    "    roc_score = roc_auc_score( temp['is_pathogenic'], temp[col])\n",
    "    mwu = mannwhitneyu(patho[col], non_patho[col])\n",
    "    mwu_scores.append([col, mwu.pvalue, mwu.statistic, roc_score])\n",
    "\n",
    "mwu_scores_df = pd.DataFrame(mwu_scores, columns=['col', 'pvalue', 'statistic', 'roc_score'])\n",
    "mwu_scores_df['-log10(pvalue)'] = -np.log10(mwu_scores_df['pvalue'])\n",
    "\n",
    "plt.figure()\n",
    "sns.barplot(x='col', y='-log10(pvalue)', data=mwu_scores_df)\n",
    "plt.title('Pathogenic all vs Benign all\\nMann-Whitney U Test -log10(pvalue)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.figure()\n",
    "plt.xticks(rotation=45)\n",
    "sns.barplot(x='col', y='roc_score', data=mwu_scores_df)\n",
    "plt.ylim(0.5, 1)\n",
    "plt.title('Pathogenic all vs Benign all\\nROC Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = dset.filter(~pl.col('in_splice_junction')).to_pandas()\n",
    "temp['is_pathogenic'] = temp['is_pathogenic'].astype(bool)\n",
    "temp['match_key'] = temp['ref_codon'] + '>' + temp['alt_codon'] + '>' + temp['pli_bin'].astype(str) + '>' + temp['cds_offset_frac_bin'].astype(str)\n",
    "\n",
    "mwu_scores = []\n",
    "\n",
    "for _ in range(50):\n",
    "    # Split into pathogenic and non-pathogenic\n",
    "    patho = temp.loc[temp['is_pathogenic']]\n",
    "    non_patho = temp.loc[~temp['is_pathogenic']]\n",
    "\n",
    "    # Count trinuc_change in pathogenic\n",
    "    patho_trinuc_counts = patho['match_key'].value_counts()\n",
    "\n",
    "\n",
    "    sampled_non_patho = []\n",
    "    for trinuc, count in patho_trinuc_counts.items():\n",
    "        subset = non_patho[non_patho['match_key'] == trinuc]\n",
    "        if len(subset) >= count:\n",
    "            sampled = subset.sample(n=count)\n",
    "        else:\n",
    "            print(f\"Not enough {trinuc} in non-pathogenic data, taking all available\")\n",
    "            sampled = subset  # take all available if not enough\n",
    "        sampled_non_patho.append(sampled)\n",
    "\n",
    "    sampled_non_patho = pd.concat(sampled_non_patho, ignore_index=True)\n",
    "    # Combine back with pathogenic\n",
    "    temp_sampled = pd.concat([patho, sampled_non_patho], ignore_index=True)\n",
    "\n",
    "    for col in preds_cols + ['phylop', 'codon_freq_ratio']:\n",
    "        roc_score = roc_auc_score( temp_sampled['is_pathogenic'], temp_sampled[col])\n",
    "        mwu = mannwhitneyu(patho[col], sampled_non_patho[col])\n",
    "        mwu_scores.append([col, mwu.pvalue, mwu.statistic, roc_score])\n",
    "\n",
    "\n",
    "mwu_scores_df = pd.DataFrame(mwu_scores, columns=['col', 'pvalue', 'statistic', 'roc_score'])\n",
    "mwu_scores_df['-log10(pvalue)'] = -np.log10(mwu_scores_df['pvalue'])\n",
    "\n",
    "plt.figure()\n",
    "sns.boxplot(x='col', y='-log10(pvalue)', data=mwu_scores_df)\n",
    "plt.title('Pathogenic vs Benign matched\\nMann-Whitney U Test -log10(pvalue)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.figure()\n",
    "sns.boxplot(x='col', y='roc_score', data=mwu_scores_df)\n",
    "plt.title('Pathogenic vs Benign matched\\nROC Score')\n",
    "plt.xticks(rotation=45)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
