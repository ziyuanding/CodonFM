{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# 1-Zero-Shot-Mutation-Variant-DDD-ASD\n",
    "\n",
    "Ability for the models to seperate healthy and disease patients in cohorts for developmental disorders (DDD/ASD) (see [1])\n",
    "\n",
    "## Dataset Information\n",
    "- **Dataset**: DDD_ASD\n",
    "- **Path**: `/data/validation/processed/ddd_asd_zhouetal_processed_am.csv`\n",
    "- **Task**: Zero-shot mutation effect prediction\n",
    "- **Models**: Pretrained Encodon models (80M, 600M, 1B)\n",
    "- **Evaluation**: Mann-Whitney U test between healthy and disease patients (-log10p) significant test values.\n",
    "\n",
    "[1] Zhou, Xueya, et al. \"Integrating de novo and inherited variants in 42,607 autism cases identifies mutations in new moderate-risk genes.\" Nature genetics 54.9 (2022): 1305-1319."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import polars as pl\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional, Any\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import pickle\n",
    "import json\n",
    "from datetime import datetime\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Machine learning libraries\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Add project paths\n",
    "sys.path.append('..')\n",
    "\n",
    "# Import Encodon-specific modules\n",
    "from src.inference.encodon import EncodonInference\n",
    "from src.inference.task_types import TaskTypes\n",
    "from src.tokenizer import Tokenizer\n",
    "from src.data.metadata import MetadataFields, MetadataConstants\n",
    "from src.data.mutation_dataset import MutationDataset, collate_fn\n",
    "from src.data.preprocess.mutation_pred import mlm_process_item\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU device: {torch.cuda.get_device_name()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## 2. Load Encodon Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_encodon_inference_model(checkpoint_path: str, device: str = \"cuda\") -> EncodonInference:\n",
    "    \"\"\"\n",
    "    Load pretrained Encodon model using the inference wrapper.\n",
    "    \n",
    "    Args:\n",
    "        checkpoint_path: Path to the pretrained checkpoint\n",
    "        device: Device to load model on ('cuda' or 'cpu')\n",
    "        \n",
    "    Returns:\n",
    "        EncodonInference object ready for mutation prediction\n",
    "    \"\"\"\n",
    "    print(f\"Loading Encodon model from: {checkpoint_path}\")\n",
    "    \n",
    "    # Create inference wrapper\n",
    "    inference_model = EncodonInference(\n",
    "        model_path=checkpoint_path,\n",
    "        task_type=TaskTypes.MUTATION_PREDICTION\n",
    "    )\n",
    "    \n",
    "    # Configure the model (loads checkpoint and tokenizer)\n",
    "    inference_model.configure_model()\n",
    "    inference_model.eval()\n",
    "    \n",
    "    print(f\"‚úÖ Model loaded successfully on {device}\")\n",
    "    print(f\"Model parameters: {sum(p.numel() for p in inference_model.model.parameters()):,}\")\n",
    "    print(f\"Tokenizer vocabulary size: {inference_model.tokenizer.vocab_size}\")\n",
    "    \n",
    "    return inference_model\n",
    "\n",
    "\n",
    "# Define checkpoint paths to try (update these to your actual paths)\n",
    "ckpt_path = \"./\"\n",
    "checkpoint_paths = {\n",
    "    \"80M\": f\"{ckpt_path}/NV-CodonFM-Encodon-80M-v1/NV-CodonFM-Encodon-80M-v1.safetensors\",\n",
    "    \"600m\": f\"{ckpt_path}/NV-CodonFM-Encodon-600M-v1/NV-CodonFM-Encodon-600M-v1.safetensors\",\n",
    "    \"1B\": f\"{ckpt_path}/NV-CodonFM-Encodon-1B-v1/NV-CodonFM-Encodon-1B-v1.safetensors\",\n",
    "    \"1B_cdwt\": f\"{ckpt_path}/NV-CodonFM-Encodon-Cdwt-1B-v1/NV-CodonFM-Encodon-Cdwt-1B-v1.safetensors\"\n",
    "}\n",
    "\n",
    "\n",
    "model_loaded = False\n",
    "encodon_models = {}\n",
    "\n",
    "for size, checkpoint_path in checkpoint_paths.items():\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        try:\n",
    "            device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "            model = load_encodon_inference_model(checkpoint_path, device=device)\n",
    "            \n",
    "            # Extract model name from path\n",
    "            model_name = os.path.basename(os.path.dirname(os.path.dirname(checkpoint_path)))\n",
    "            display_name = f\"EnCodon ({size})\"\n",
    "            \n",
    "            encodon_models[display_name] = {\n",
    "                'model': model,\n",
    "                'path': checkpoint_path,\n",
    "                'device': device\n",
    "            }\n",
    "            print(f\"‚úÖ Successfully loaded {display_name} from: {checkpoint_path}\")\n",
    "            model_loaded = True\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to load from {checkpoint_path}: {e}\")\n",
    "            continue\n",
    "\n",
    "if not model_loaded:\n",
    "    print(\"‚ùå Could not load any Encodon model from the specified paths.\")\n",
    "    print(\"Please ensure a checkpoint exists or update the checkpoint_paths list.\")\n",
    "else:\n",
    "    print(f\"\\n‚úÖ Loaded {len(encodon_models)} models: {list(encodon_models.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## 3. Define Plotting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_size_key(model):\n",
    "    \"\"\"Helper to determine model size from its name - consistent with generate_results.py.\"\"\"\n",
    "    name = model.lower()\n",
    "    if '80m' in name:\n",
    "        return (0, '80M')  \n",
    "    elif '600m' in name:\n",
    "        return (1, '600M')  \n",
    "    elif '1b' in name:\n",
    "        return (2, '1B') \n",
    "    else:\n",
    "        return (99, 'Unknown')\n",
    "\n",
    "\n",
    "def calculate_mutation_separation_metrics(df, model_columns, dataset_info):\n",
    "    \"\"\"Calculate separation metrics using Mann-Whitney U test for DDD_ASD dataset.\"\"\"\n",
    "    metrics = {}\n",
    "    cls_col = dataset_info['comparison_column']\n",
    "    model_columns = list(model_columns.items())\n",
    "    if 'baseline_column' in dataset_info:\n",
    "        model_columns.append(('Baseline', dataset_info['baseline_column']))\n",
    "    \n",
    "    for model_name, col in model_columns:\n",
    "        metrics[model_name] = {}\n",
    "        for expt_str, ctrl_str in dataset_info['comparisons']:\n",
    "            # Get predictions for experimental and control groups\n",
    "            preds = df.loc[df[cls_col].str.contains(expt_str)].groupby('variant_id')[col].mean()\n",
    "            ctrls = df.loc[df[cls_col].str.contains(ctrl_str)].groupby('variant_id')[col].mean()\n",
    "            \n",
    "            # Perform Mann-Whitney U test\n",
    "            stat, p = mannwhitneyu(preds, ctrls)\n",
    "            metrics[model_name][expt_str] = {\n",
    "                'n_expt': len(preds),\n",
    "                'n_ctrl': len(ctrls),\n",
    "                'stat': stat,\n",
    "                'p': p, \n",
    "                '-log10(p)': -np.log10(p)\n",
    "            }\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def _assign_bar_colors_for_separation(df_group):\n",
    "    \"\"\"Assign unique colors to each bar based on model size - consistent with generate_results.py.\"\"\"\n",
    "    # Use same base colors as generate_results.py\n",
    "    base_colors = {\n",
    "        '80M': (0.0, 0.4, 0.8),      # Blue\n",
    "        '600M': (1.0, 0.5, 0.0),     # Orange\n",
    "        '1B': (0.0, 0.7, 0.0),        # Green\n",
    "        'baseline': (0.1, 0.1, 0.1), # almost black\n",
    "        'other': (0.5, 0.5, 0.5) # grey\n",
    "    }\n",
    "    \n",
    "    # Assign a \"size\" column if not present\n",
    "    if 'size' not in df_group.columns:\n",
    "        def extract_size(model_name):\n",
    "            match = get_size_key(model_name)[1]\n",
    "            if match in base_colors:\n",
    "                return match\n",
    "            elif \"baseline\" in model_name.lower():\n",
    "                return \"baseline\"\n",
    "            else:\n",
    "                return \"other\"\n",
    "        df_group = df_group.copy()\n",
    "        df_group['size'] = df_group['model'].apply(extract_size)\n",
    "\n",
    "    # Use -log10(p) to determine brightness: scale between 0.4 and 1.0\n",
    "    log10p = df_group['-log10(p)'].values\n",
    "    # Avoid NaN/inf\n",
    "    log10p = np.nan_to_num(log10p, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "    bar_colors = []\n",
    "    for i, size in enumerate(df_group['size']):\n",
    "        if size not in base_colors:\n",
    "            base_color = base_colors['other']\n",
    "        else:\n",
    "            base_color = base_colors[size]\n",
    "        # For Baseline, always use the base color\n",
    "        if size == 'baseline':\n",
    "            bar_colors.append(base_color)\n",
    "            continue\n",
    "        \n",
    "        bar_colors.append(base_color)\n",
    "    return bar_colors\n",
    "\n",
    "\n",
    "def plot_separation_metrics_bar(df_metrics, dataset_name):\n",
    "    \"\"\"Plot separation metrics as bar plots for each group - ordered by model size.\"\"\"\n",
    "    for g in df_metrics['group'].unique():\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "        df_group = df_metrics[df_metrics['group'] == g].copy()\n",
    "        df_group['size'] = df_group['model'].apply(lambda x: get_size_key(x)[1])\n",
    "        \n",
    "        # Sort models by size (80M, 600M, 1B) then by name for consistent ordering\n",
    "        def sort_key(row):\n",
    "            size_order, size_str = get_size_key(row['model'])\n",
    "            if 'baseline' in row['model'].lower():\n",
    "                return (999, row['model'])  # Put baseline at the end\n",
    "            return (size_order, row['model'])\n",
    "        \n",
    "        df_group['sort_key'] = df_group.apply(sort_key, axis=1)\n",
    "        df_group = df_group.sort_values('sort_key').reset_index(drop=True)\n",
    "        df_group = df_group.drop('sort_key', axis=1)\n",
    "        \n",
    "        # Assign bar colors using the adapted function\n",
    "        bar_colors = _assign_bar_colors_for_separation(df_group)\n",
    "        \n",
    "        # Create horizontal bar plot\n",
    "        sns.barplot(\n",
    "            y='model', \n",
    "            x='-log10(p)', \n",
    "            data=df_group, \n",
    "            orient='h', \n",
    "            hue='model',\n",
    "            palette=bar_colors,\n",
    "            legend=False,\n",
    "            ax=ax,\n",
    "            order=df_group['model']  # Use the sorted order\n",
    "        )\n",
    "        \n",
    "        # Add value annotations\n",
    "        for i, (value, model) in enumerate(zip(df_group['-log10(p)'], df_group['model'])):\n",
    "            ax.text(value + 0.1, i, f\"{value:.2f}\", va='center', ha='left', fontsize=10, color='black')\n",
    "        \n",
    "        ax.set_xlabel('-log10(p)', fontsize=12)\n",
    "        ax.set_ylabel('Model', fontsize=12)\n",
    "        \n",
    "        # Get n_expt and n_ctrl from the first row\n",
    "        n_expt = df_group['n_expt'].iloc[0] if 'n_expt' in df_group.columns else None\n",
    "        n_ctrl = df_group['n_ctrl'].iloc[0] if 'n_ctrl' in df_group.columns else None\n",
    "        title_str = f\"{g.upper()}\"\n",
    "        if n_expt is not None and n_ctrl is not None:\n",
    "            title_str += f\" (n_expt={n_expt}, n_ctrl={n_ctrl})\"\n",
    "        ax.set_title(title_str, fontsize=14, fontweight='bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{dataset_name}_{g}_separation.png\", dpi=300, bbox_inches='tight', facecolor='white')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "print(\"‚úÖ Separation analysis functions defined with consistent ordering and colors!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## 4. Load DDD_ASD Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DDD_ASD dataset\n",
    "DATASET_CONFIG = {\n",
    "    'key': 'ddd_asd_zhouetal',\n",
    "    'name': 'DDD_ASD',\n",
    "    'data_path': '/data/validation/processed/ddd_asd_zhouetal_processed_am.csv',\n",
    "    'description': 'Combined DDD and ASD variants for separation analysis, processed according to Zhou et al. methodology.'\n",
    "}\n",
    "\n",
    "def load_dataset(config):\n",
    "    \"\"\"Load and inspect the DDD_ASD dataset.\"\"\"\n",
    "    print(f\"Loading {config['name']} dataset...\")\n",
    "    print(f\"Path: {config['data_path']}\")\n",
    "    \n",
    "    if not os.path.exists(config['data_path']):\n",
    "        print(f\"‚ùå Dataset not found: {config['data_path']}\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Load data using polars then convert to pandas\n",
    "        data = pl.read_csv(config['data_path'], ignore_errors=True).to_pandas()\n",
    "        print(f\"‚úÖ Loaded {len(data)} variants\")\n",
    "        print(f\"Shape: {data.shape}\")\n",
    "        print(f\"Columns: {list(data.columns)}\")\n",
    "        \n",
    "        # Check for required columns\n",
    "        required_cols = ['id', 'ref_seq', 'ref_codon', 'alt_codon', 'codon_position']\n",
    "        missing_cols = [col for col in required_cols if col not in data.columns]\n",
    "        \n",
    "        if missing_cols:\n",
    "            print(f\"‚ö†Ô∏è Missing columns: {missing_cols}\")\n",
    "        else:\n",
    "            print(\"‚úÖ All required columns present\")\n",
    "        \n",
    "\n",
    "        \n",
    "        # Show sample data\n",
    "        display_cols = [col for col in ['id', 'ref_codon', 'alt_codon', 'codon_position', 'classification'] if col in data.columns]\n",
    "        print(f\"\\nSample data:\")\n",
    "        print(data[display_cols].head(3))\n",
    "        \n",
    "        return data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to load dataset: {e}\")\n",
    "        return None\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset(DATASET_CONFIG)\n",
    "print(f\"\\nüìä Dataset loaded: {dataset is not None}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## 5. Run Mutation Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_mutation_predictions(models, data):\n",
    "    \"\"\"Run mutation predictions for DDD_ASD dataset.\"\"\"\n",
    "    if data is None or not models:\n",
    "        print(\"‚ùå No data or models available\")\n",
    "        return {}\n",
    "    \n",
    "    print(f\"\\n=== RUNNING MUTATION PREDICTIONS FOR DDD_ASD ===\")\n",
    "    \n",
    "\n",
    "    data_subset = data.copy()\n",
    "    \n",
    "    all_predictions = {}\n",
    "    \n",
    "    for model_name, model_info in models.items():\n",
    "        print(f\"\\n--- Processing {model_name} ---\")\n",
    "        \n",
    "        # Create temporary CSV file\n",
    "        temp_csv_path = f\"/tmp/ddd_asd_zhouetal_{model_name.replace(' ', '_')}_temp.csv\"\n",
    "        data_subset.to_csv(temp_csv_path, index=False)\n",
    "        \n",
    "        try:\n",
    "            # Create MutationDataset\n",
    "            mutation_dataset = MutationDataset(\n",
    "                data_path=temp_csv_path,\n",
    "                tokenizer=model_info['model'].tokenizer,\n",
    "                process_item=mlm_process_item,\n",
    "                context_length=2048,\n",
    "                task=\"mlm\",\n",
    "                extract_seq=True,\n",
    "                train_val_test_ratio=None\n",
    "            )\n",
    "            \n",
    "            # Create DataLoader\n",
    "            dataloader = torch.utils.data.DataLoader(\n",
    "                mutation_dataset,\n",
    "                batch_size=32,\n",
    "                shuffle=False,\n",
    "                collate_fn=collate_fn,\n",
    "                num_workers=0\n",
    "            )\n",
    "            \n",
    "            # Run predictions\n",
    "            all_ids = []\n",
    "            all_likelihood_ratios = []\n",
    "            \n",
    "            model_info['model'].eval()\n",
    "            model_info['model'].to(model_info['device'])\n",
    "            with torch.no_grad():\n",
    "                for batch in tqdm(dataloader, desc=f\"{model_name} predictions\"):\n",
    "                    # Move batch to device\n",
    "                    for key in batch:\n",
    "                        if isinstance(batch[key], torch.Tensor):\n",
    "                            batch[key] = batch[key].to(model_info['device'])\n",
    "                    \n",
    "                    # Get predictions\n",
    "                    output = model_info['model'].predict_mutation(batch, ids=batch[MetadataFields.ID])\n",
    "                    \n",
    "                    all_ids.extend(output.ids)\n",
    "                    all_likelihood_ratios.extend(output.likelihood_ratios)\n",
    "            \n",
    "            all_predictions[model_name] = {\n",
    "                'ids': np.array(all_ids),\n",
    "                'likelihood_ratios': np.array(all_likelihood_ratios)\n",
    "            }\n",
    "            \n",
    "            print(f\"‚úÖ Completed {len(all_ids)} predictions\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed predictions for {model_name}: {e}\")\n",
    "            continue\n",
    "        finally:\n",
    "            # Clean up temporary file\n",
    "            if os.path.exists(temp_csv_path):\n",
    "                os.remove(temp_csv_path)\n",
    "            \n",
    "            # Offload model from GPU to free memory\n",
    "            if 'model' in model_info and hasattr(model_info['model'], 'cpu'):\n",
    "                model_info['model'].cpu()\n",
    "                print(f\"üîÑ Offloaded {model_name} from GPU\")\n",
    "            \n",
    "            # Clear GPU cache\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "                print(f\"üßπ Cleared GPU cache after {model_name}\")\n",
    "    \n",
    "    return all_predictions\n",
    "\n",
    "# Run predictions if models and dataset are available\n",
    "if 'encodon_models' in locals() and 'dataset' in locals() and dataset is not None:\n",
    "    predictions = run_mutation_predictions(encodon_models, dataset)\n",
    "    print(f\"\\n‚úÖ Predictions completed for {len(predictions)} models\")\n",
    "else:\n",
    "    print(\"‚ùå Cannot run predictions - missing models or dataset\")\n",
    "    predictions = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## 6. Evaluate Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_and_plot_ddd_asd_zhouetal_results(predictions, data):\n",
    "    \"\"\"Evaluate and plot separation results for DDD_ASD dataset.\"\"\"\n",
    "    if not predictions or data is None:\n",
    "        print(\"‚ùå No predictions or data available\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\n=== EVALUATING DDD_ASD SEPARATION RESULTS ===\")\n",
    "    \n",
    "    # Create evaluation dataframe\n",
    "    eval_df = data.copy()\n",
    "    model_columns = {}\n",
    "    \n",
    "    for model_name, pred_data in predictions.items():\n",
    "        # Create mapping from ID to likelihood ratio\n",
    "        id_to_lr = dict(zip(pred_data['ids'], pred_data['likelihood_ratios']))\n",
    "        \n",
    "        # Add predictions to dataframe\n",
    "        col_name = f\"likelihood_ratios_{model_name}\"\n",
    "        eval_df[col_name] = eval_df['id'].map(id_to_lr)\n",
    "        model_columns[model_name] = col_name\n",
    "        \n",
    "        # Report coverage\n",
    "        coverage = eval_df[col_name].notna().sum()\n",
    "        print(f\"{model_name}: {coverage}/{len(eval_df)} variants ({coverage/len(eval_df)*100:.1f}%)\")\n",
    "    \n",
    "    # Filter to complete cases\n",
    "    mask = pd.Series(True, index=eval_df.index)\n",
    "    for col in model_columns.values():\n",
    "        mask &= ~eval_df[col].isna()\n",
    "    \n",
    "    eval_df_filtered = eval_df[mask]\n",
    "    print(f\"\\nEvaluation set: {len(eval_df_filtered)} variants with complete predictions\")\n",
    "    \n",
    "    if len(eval_df_filtered) < 10:\n",
    "        print(\"‚ö†Ô∏è Too few samples for reliable evaluation\")\n",
    "        return\n",
    "    \n",
    "    # Define dataset configuration for separation analysis\n",
    "    dataset_info = {\n",
    "        'comparison_column': 'classification',\n",
    "        'comparisons': [('ddd', 'control'), ('asd', 'control')],\n",
    "        'baseline_column': 'AlphaMissense'\n",
    "    }\n",
    "    \n",
    "    # Calculate separation metrics\n",
    "    metrics = calculate_mutation_separation_metrics(eval_df_filtered, model_columns, dataset_info)\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\nüìä Separation Analysis Summary:\")\n",
    "    for model_name in metrics.keys():\n",
    "        print(f\"\\n{model_name}:\")\n",
    "        for group, stats in metrics[model_name].items():\n",
    "            print(f\"  {group.upper()}: -log10(p) = {stats['-log10(p)']:.2f}, p = {stats['p']:.2e}\")\n",
    "            print(f\"    n_expt = {stats['n_expt']}, n_ctrl = {stats['n_ctrl']}\")\n",
    "    \n",
    "    # Create DataFrame for plotting\n",
    "    records = []\n",
    "    for model, groups in metrics.items():\n",
    "        for group, stats in groups.items():\n",
    "            record = {'model': model, 'group': group}\n",
    "            record.update(stats)\n",
    "            records.append(record)\n",
    "    \n",
    "    df_metrics = pd.DataFrame(records)\n",
    "    \n",
    "    # Create plots\n",
    "    plot_separation_metrics_bar(df_metrics, 'DDD_ASD')\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Run separation analysis evaluation\n",
    "if 'predictions' in locals() and 'dataset' in locals():\n",
    "    results = evaluate_and_plot_ddd_asd_zhouetal_results(predictions, dataset)\n",
    "else:\n",
    "    print(\"‚ùå No predictions or dataset available for evaluation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## 7. Save/Load Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and load functionality for DDD_ASD\n",
    "def save_ddd_asd_zhouetal_results(predictions, filename='ddd_asd_zhouetal_results.pkl'):\n",
    "    \"\"\"Save DDD_ASD prediction results.\"\"\"\n",
    "    results_to_save = {\n",
    "        'predictions': predictions,\n",
    "        'dataset_key': 'ddd_asd_zhouetal',\n",
    "        'dataset_name': 'DDD_ASD',\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'models': list(predictions.keys()) if predictions else []\n",
    "    }\n",
    "    \n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(results_to_save, f)\n",
    "    \n",
    "    print(f\"‚úÖ DDD_ASD results saved to {filename}\")\n",
    "    print(f\"   Models: {results_to_save['models']}\")\n",
    "    print(f\"   Timestamp: {results_to_save['timestamp']}\")\n",
    "\n",
    "def load_ddd_asd_zhouetal_results(filename='ddd_asd_zhouetal_results.pkl'):\n",
    "    \"\"\"Load DDD_ASD prediction results.\"\"\"\n",
    "    if not os.path.exists(filename):\n",
    "        print(f\"‚ùå Results file not found: {filename}\")\n",
    "        return {}\n",
    "    \n",
    "    with open(filename, 'rb') as f:\n",
    "        results = pickle.load(f)\n",
    "    \n",
    "    print(f\"‚úÖ DDD_ASD results loaded from {filename}\")\n",
    "    print(f\"   Models: {results.get('models', [])}\")\n",
    "    print(f\"   Timestamp: {results.get('timestamp', 'Unknown')}\")\n",
    "    \n",
    "    return results.get('predictions', {})\n",
    "\n",
    "# Save current results if available\n",
    "if 'predictions' in locals() and predictions:\n",
    "    save_ddd_asd_zhouetal_results(predictions)\n",
    "    print(f\"\\nüíæ DDD_ASD results saved!\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è No DDD_ASD results to save yet\")\n",
    "\n",
    "# Try to load existing results\n",
    "if os.path.exists('ddd_asd_zhouetal_results.pkl'):\n",
    "    saved_predictions = load_ddd_asd_zhouetal_results()\n",
    "    if saved_predictions and not locals().get('predictions'):\n",
    "        predictions = saved_predictions\n",
    "        print(f\"   Using saved results for analysis\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
