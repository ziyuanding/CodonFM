{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a41db4-788e-4dd3-84a9-0e4d9dbbdf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "import os\n",
    "import urllib\n",
    "from tqdm import tqdm\n",
    "import gzip\n",
    "import re\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from tqdm import tqdm  # Progress bar\n",
    "\n",
    "import polars as pl\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9247159-241b-4276-804a-ac0fbeafab84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "import polars as pl\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import sys\n",
    "\n",
    "dna_code = {\n",
    "    \"ATA\": \"I\",\n",
    "    \"ATC\": \"I\",\n",
    "    \"ATT\": \"I\",\n",
    "    \"ATG\": \"M\",\n",
    "    \"ACA\": \"T\",\n",
    "    \"ACC\": \"T\",\n",
    "    \"ACG\": \"T\",\n",
    "    \"ACT\": \"T\",\n",
    "    \"AAC\": \"N\",\n",
    "    \"AAT\": \"N\",\n",
    "    \"AAA\": \"K\",\n",
    "    \"AAG\": \"K\",\n",
    "    \"AGC\": \"S\",\n",
    "    \"AGT\": \"S\",\n",
    "    \"AGA\": \"R\",\n",
    "    \"AGG\": \"R\",\n",
    "    \"CTA\": \"L\",\n",
    "    \"CTC\": \"L\",\n",
    "    \"CTG\": \"L\",\n",
    "    \"CTT\": \"L\",\n",
    "    \"CCA\": \"P\",\n",
    "    \"CCC\": \"P\",\n",
    "    \"CCG\": \"P\",\n",
    "    \"CCT\": \"P\",\n",
    "    \"CAC\": \"H\",\n",
    "    \"CAT\": \"H\",\n",
    "    \"CAA\": \"Q\",\n",
    "    \"CAG\": \"Q\",\n",
    "    \"CGA\": \"R\",\n",
    "    \"CGC\": \"R\",\n",
    "    \"CGG\": \"R\",\n",
    "    \"CGT\": \"R\",\n",
    "    \"GTA\": \"V\",\n",
    "    \"GTC\": \"V\",\n",
    "    \"GTG\": \"V\",\n",
    "    \"GTT\": \"V\",\n",
    "    \"GCA\": \"A\",\n",
    "    \"GCC\": \"A\",\n",
    "    \"GCG\": \"A\",\n",
    "    \"GCT\": \"A\",\n",
    "    \"GAC\": \"D\",\n",
    "    \"GAT\": \"D\",\n",
    "    \"GAA\": \"E\",\n",
    "    \"GAG\": \"E\",\n",
    "    \"GGA\": \"G\",\n",
    "    \"GGC\": \"G\",\n",
    "    \"GGG\": \"G\",\n",
    "    \"GGT\": \"G\",\n",
    "    \"TCA\": \"S\",\n",
    "    \"TCC\": \"S\",\n",
    "    \"TCG\": \"S\",\n",
    "    \"TCT\": \"S\",\n",
    "    \"TTC\": \"F\",\n",
    "    \"TTT\": \"F\",\n",
    "    \"TTA\": \"L\",\n",
    "    \"TTG\": \"L\",\n",
    "    \"TAC\": \"Y\",\n",
    "    \"TAT\": \"Y\",\n",
    "    \"TAA\": \"*\",\n",
    "    \"TAG\": \"*\",\n",
    "    \"TGC\": \"C\",\n",
    "    \"TGT\": \"C\",\n",
    "    \"TGA\": \"*\",\n",
    "    \"TGG\": \"W\",\n",
    "}\n",
    "AA = set(dna_code.values())\n",
    "idxes = [13,49,0,4,52,7,63,29,19,35,43,14,3,33,57,24,60,5,56,59,21,11,28,55,62,58,30,26,22,\n",
    "         48,17,12,10,23,44,15,20,27,40,9,8,54,38,37,16,36,32,18,34,39,31,46,2,42,53,6,61,25,47,50,51,45,41,1]\n",
    "dna_codon_idx = {k:i for i,k in zip(idxes, dna_code.keys())}\n",
    "dna_codon_idx['---'] = -1\n",
    "\n",
    "# Define the genetic code as a dictionary mapping codons to amino acids\n",
    "rna_code = {\n",
    "    \"UUU\": \"F\",\n",
    "    \"UUC\": \"F\",  # Phenylalanine\n",
    "    \"UUA\": \"L\",\n",
    "    \"UUG\": \"L\",  # Leucine\n",
    "    \"UCU\": \"S\",\n",
    "    \"UCC\": \"S\",\n",
    "    \"UCA\": \"S\",\n",
    "    \"UCG\": \"S\",  # Serine\n",
    "    \"UAU\": \"Y\",\n",
    "    \"UAC\": \"Y\",  # Tyrosine\n",
    "    \"UAA\": \"*\",\n",
    "    \"UAG\": \"*\",  # Stop codons\n",
    "    \"UGA\": \"*\",  # Stop codon\n",
    "    \"UGU\": \"C\",\n",
    "    \"UGC\": \"C\",  # Cysteine\n",
    "    \"UGG\": \"W\",  # Tryptophan\n",
    "    \"CUU\": \"L\",\n",
    "    \"CUC\": \"L\",\n",
    "    \"CUA\": \"L\",\n",
    "    \"CUG\": \"L\",\n",
    "    \"CCU\": \"P\",\n",
    "    \"CCC\": \"P\",\n",
    "    \"CCA\": \"P\",\n",
    "    \"CCG\": \"P\",\n",
    "    \"CAU\": \"H\",\n",
    "    \"CAC\": \"H\",  # Histidine\n",
    "    \"CAA\": \"Q\",\n",
    "    \"CAG\": \"Q\",  # Glutamine\n",
    "    \"CGU\": \"R\",\n",
    "    \"CGC\": \"R\",\n",
    "    \"CGA\": \"R\",\n",
    "    \"CGG\": \"R\",\n",
    "    \"AUU\": \"I\",\n",
    "    \"AUC\": \"I\",\n",
    "    \"AUA\": \"I\",\n",
    "    \"AUG\": \"M\",  # Methionine (start codon)\n",
    "    \"ACU\": \"T\",\n",
    "    \"ACC\": \"T\",\n",
    "    \"ACA\": \"T\",\n",
    "    \"ACG\": \"T\",\n",
    "    \"AAU\": \"N\",\n",
    "    \"AAC\": \"N\",\n",
    "    \"AAA\": \"K\",\n",
    "    \"AAG\": \"K\",\n",
    "    \"AGU\": \"S\",\n",
    "    \"AGC\": \"S\",\n",
    "    \"AGA\": \"R\",\n",
    "    \"AGG\": \"R\",\n",
    "    \"GUU\": \"V\",\n",
    "    \"GUC\": \"V\",\n",
    "    \"GUA\": \"V\",\n",
    "    \"GUG\": \"V\",\n",
    "    \"GCU\": \"A\",\n",
    "    \"GCC\": \"A\",\n",
    "    \"GCA\": \"A\",\n",
    "    \"GCG\": \"A\",\n",
    "    \"GAU\": \"D\",\n",
    "    \"GAC\": \"D\",\n",
    "    \"GAA\": \"E\",\n",
    "    \"GAG\": \"E\",\n",
    "    \"GGU\": \"G\",\n",
    "    \"GGC\": \"G\",\n",
    "    \"GGA\": \"G\",\n",
    "    \"GGG\": \"G\",\n",
    "}\n",
    "\n",
    "rna_codon_idx = {k:i for i,k in zip(idxes, rna_code.keys())}\n",
    "\n",
    "def translate(seq, codon_dict):\n",
    "    \"\"\"\n",
    "    Translate an RNA sequence into a protein sequence.\n",
    "    Stops translation when a stop codon ('*') is encountered.\n",
    "    \"\"\"\n",
    "    is_str = isinstance(list(codon_dict.values())[0], str)\n",
    "    if is_str:\n",
    "        protein = \"\"\n",
    "    else:\n",
    "        protein = []\n",
    "    # Process the RNA sequence three nucleotides (codon) at a time.\n",
    "    for i in range(0, len(seq) - 2, 3):\n",
    "        codon = seq[i : i + 3]\n",
    "        # Look up the codon in the genetic code dictionary.\n",
    "        \n",
    "        if is_str:\n",
    "            amino_acid = codon_dict.get(codon, \"?\")\n",
    "            protein += amino_acid\n",
    "        else:\n",
    "            amino_acid = codon_dict[codon]\n",
    "            protein.append(amino_acid)\n",
    "            \n",
    "    return protein"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7e3ccd",
   "metadata": {},
   "source": [
    "## Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dba5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The file can be downloaded from https://ftp.ncbi.nlm.nih.gov/genomes/refseq/assembly_summary_refseq.txt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd849c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://ftp.ncbi.nlm.nih.gov/genomes/refseq/assembly_summary_refseq.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2592ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE: that this file may be changing. The models were trained with release version 228 downloaded on Mar-10-2025\n",
    "meta = pd.read_table('/data/codonfm/assembly_summary_refseq.txt', skiprows=1,low_memory=False)\n",
    "meta = meta.loc[(meta['refseq_category']=='reference genome')]\n",
    "\n",
    "meta.groupby('group')['#assembly_accession'].apply(lambda x:x.unique().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258ce848",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "taxids_to_remove = sum([v for _,v in json.load(open('taxids_to_remove_bac.json')).items()], [])\n",
    "\n",
    "meta = meta.loc[~meta['taxid'].isin(taxids_to_remove)]\n",
    "meta.groupby('group')['#assembly_accession'].apply(lambda x:x.unique().shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fadfa3",
   "metadata": {},
   "source": [
    "We need the taxonomy trees from NCBI to get the Primates\n",
    "\n",
    "The taxonomy dump can be obtained from https://ftp.ncbi.nlm.nih.gov/pub/taxonomy/taxdmp.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2594f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!wget https://ftp.ncbi.nlm.nih.gov/pub/taxonomy/taxdmp.zip\n",
    "!unzip taxdmp.zip\n",
    "!rm taxdmp.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4531895d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_files(ftp_paths, destination_folder='downloads'):\n",
    "    if not os.path.exists(destination_folder):\n",
    "        os.makedirs(destination_folder)\n",
    "    \n",
    "    for ftp_path in tqdm(ftp_paths):\n",
    "        \n",
    "        parent_dir_name = ftp_path.split('/')[-1]\n",
    "        curr_dir = os.path.join(destination_folder, parent_dir_name[:10])\n",
    "        if not os.path.exists( curr_dir):\n",
    "            os.makedirs(curr_dir)\n",
    "        file_name = parent_dir_name + '_cds_from_genomic.fna.gz'\n",
    "        file_url = f\"{ftp_path}/{file_name}\"\n",
    "        local_file_path = os.path.join(curr_dir, file_name)\n",
    "        \n",
    "        try:\n",
    "            urllib.request.urlretrieve(file_url, local_file_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to download {file_url}. Error: {e}\")\n",
    "\n",
    "download_files(meta['ftp_path'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febcef66-7667-4a31-be32-3a27eeeb9f58",
   "metadata": {},
   "source": [
    "## Sequence processing after downloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6eea5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load tax-id to name mapping\n",
    "tax_id_to_name = {}\n",
    "with open('names.dmp', 'r') as f:\n",
    "    for line in f:\n",
    "        fields = line.strip().split('\\t|\\t')\n",
    "        tax_id = int(fields[0])\n",
    "        name = fields[1]\n",
    "        if name != 'scientific name':\n",
    "            tax_id_to_name[tax_id] = name\n",
    "\n",
    "# Load tax-id to parent mapping\n",
    "tax_id_to_parent = {}\n",
    "with open('nodes.dmp', 'r') as f:\n",
    "    for line in f:\n",
    "        fields = line.strip().split('\\t|\\t')\n",
    "        tax_id = int(fields[0])\n",
    "        parent_id = int(fields[1])\n",
    "        tax_id_to_parent[tax_id] = parent_id\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load names.dmp into a dictionary\n",
    "names_dict = {}\n",
    "with open('names.dmp', 'r') as f:\n",
    "    for line in f:\n",
    "        fields = line.strip().split('\\t|\\t')\n",
    "        tax_id = int(fields[0])\n",
    "        name = fields[1]\n",
    "        if name != 'scientific name':\n",
    "            names_dict[name] = tax_id\n",
    "\n",
    "# Map organisms to taxonomy IDs\n",
    "organisms = [\"Xenopus tropicalis\", \"Homo sapiens\"]\n",
    "tax_ids = {org: names_dict.get(org) for org in organisms}\n",
    "\n",
    "print(tax_ids)\n",
    "\n",
    "to_class = [names_dict['viruses'], names_dict['bacteria'],\n",
    "           names_dict['Primates'], names_dict['Rodentia'], names_dict['Mammalia'], \n",
    "            names_dict['Phage sp.'],\n",
    "           names_dict['invertebrate metagenome'], names_dict['Fungi'],\n",
    "           names_dict['Viridiplantae'], names_dict['vertebrates']]\n",
    "\n",
    "to_class_names = ['viruses','bacteria','Primates','Rodents','Mammals','Phage',\n",
    "                  'invertebrate', 'fungi','plants', 'vertebrates', 'others']\n",
    "\n",
    "ref_classes = {}\n",
    "for t in tqdm(meta['taxid'].values):\n",
    "    tt = t\n",
    "    if t not in tax_id_to_parent:\n",
    "        continue\n",
    "    while t not in to_class:\n",
    "        nt = tax_id_to_parent[t]\n",
    "        if nt == t:\n",
    "            break\n",
    "        else:\n",
    "            t = nt\n",
    "    if t in to_class:\n",
    "        ref_classes[tt]= to_class_names[to_class.index(t)]\n",
    "    else:\n",
    "        ref_classes[tt]= to_class_names[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735da291-bd9c-4842-a9f2-5fe5ec9e9554",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def check_sequence(seq):\n",
    "    if len(seq) %3 == 0:\n",
    "        aa = translate(seq, dna_code)\n",
    "        if len(set(aa).difference(AA)) == 0:\n",
    "            if '*' not in aa.rstrip('*'):\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "\n",
    "assembly_to_taxid = {a:b for a,b in meta[['#assembly_accession','taxid']].values}\n",
    "assembly_to_group = {a:b for a,b in meta[['#assembly_accession','group']].values}\n",
    "def process_file(fn, output_dir):\n",
    "    # Extract the assembly ID\n",
    "    match = re.search(r'GCF_\\d+\\.\\d+', fn)\n",
    "    if not match:\n",
    "        print(f\"No match found for assembly in filename: {fn}\")\n",
    "        return\n",
    "    assembly = match.group(0)\n",
    "    taxid = assembly_to_taxid[assembly]\n",
    "    # Create output file for this assembly\n",
    "    group_name = assembly_to_group[assembly] if ref_classes[taxid] != 'Primates' else ref_classes[taxid]\n",
    "    output_file = os.path.join(output_dir, f\"{group_name}_{assembly}.csv\")\n",
    "\n",
    "    with gzip.open(fn, 'rt') as f: #, open(output_file, 'w') as outfile:\n",
    "        # Write the CSV header\n",
    "        parsed_data = []\n",
    "        # Process entries and write directly to the file\n",
    "        for entry in f.read().split('\\n>'):\n",
    "            lines = entry.strip().split(\"\\n\")\n",
    "            header = lines[0]\n",
    "            sequence = \"\".join(lines[1:])  # Combine all lines of the sequence\n",
    "            if check_sequence(sequence):\n",
    "                # Extract the ID (everything after 'lcl|' up to the first space)\n",
    "                match = re.search(r'lcl\\|([^ ]+)', header)\n",
    "                if match:\n",
    "                    id_ = match.group(1)\n",
    "                    # Write the entry directly to the output file\n",
    "                    parsed_data.append([assembly,group_name, taxid,id_,sequence])\n",
    "                else:\n",
    "                    print(f\"Invalid header in file {fn}: {header}\")\n",
    "                    break\n",
    "    parsed_data = pd.DataFrame(parsed_data)\n",
    "    parsed_data.columns = ['assembly','group','taxid','seq_id','cds']\n",
    "    parsed_data = parsed_data.drop_duplicates(subset='cds')\n",
    "    parsed_data.to_csv(output_file, index=False)\n",
    "    return taxid, group_name, parsed_data.shape[0]\n",
    "\n",
    "def process_files_in_parallel(files, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)  # Ensure the output directory exists\n",
    "\n",
    "    with ProcessPoolExecutor() as executor:\n",
    "        # Use tqdm to track progress\n",
    "        outputs = list(tqdm(executor.map(process_file, files, [output_dir] * len(files)), \n",
    "                  total=len(files), desc=\"Processing Files\"))\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c55470-4875-4da8-acf4-cab24e84bd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = sorted(glob('ncbi_refseq_reference/raw/*/*.fna.gz'))\n",
    "ouputs = process_files_in_parallel(files, 'ncbi_refseq_reference/processed/')\n",
    "outputs_df = pd.DataFrame(ouputs)\n",
    "outputs_df.columns = ['taxid','class','count']\n",
    "counts = outputs_df.groupby('class')['count'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d34ec65-f0c2-41de-9709-d0e053d01d50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71903717-72c9-46a7-a7a5-25b31766c396",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_counts = []\n",
    "for group in counts['class'].values:\n",
    "    \n",
    "    seqs = []\n",
    "    for fn in tqdm(glob(f'ncbi_refseq_reference/processed/{group}*.csv')):\n",
    "        seqs.append(pl.read_csv(fn))\n",
    "    seqs = pl.concat(seqs)\n",
    "    seqs = seqs.sort('taxid')\n",
    "    out = []\n",
    "    for tid in seqs['taxid'].unique():\n",
    "        temp = seqs.filter(pl.col('taxid')==tid).unique('cds')\n",
    "        out.append(temp)\n",
    "    out = pl.concat(out)\n",
    "    # if out.shape[0] != seqs.shape[0]:\n",
    "    out_fn = f'ncbi_refseq_reference/processed_grouped/{group}.csv'\n",
    "    out.write_csv(out_fn)\n",
    "    unique_counts.append([group, seqs.shape[0]])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25d6631-a3ae-4eeb-a4c6-be801063e021",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_df = pd.DataFrame(unique_counts)\n",
    "counts_df.columns = ['class','count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5f6b54-9d25-4a49-aa96-f0955663e307",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels = [f\"{cls} ({cnt:,})\" for cls, cnt in zip(counts_df['class'], counts_df['count'])]\n",
    "\n",
    "# Create the pie chart\n",
    "plt.pie(counts_df['count'], labels=labels, autopct='%1.1f%%')\n",
    "plt.title(\"Distribution of sequences across organisms\")\n",
    "plt.savefig('ncbi_refseq_reference/sequence_distribution.png',dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330e93d4-9088-471f-93fb-ba01de1cf74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta['new_group'] = [ref_classes[t] if ref_classes[t]=='Primates' else v  \n",
    "                     for a,t,v in meta[['#assembly_accession','taxid','group']].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c0d875-0ed2-40ce-b170-33cf44299055",
   "metadata": {},
   "outputs": [],
   "source": [
    "org_counts = meta['new_group'].value_counts().reset_index().values\n",
    "labels = [f\"{label} ({count})\" for label, count in org_counts if label != 'bacteria'] # Add counts to labels\n",
    "sizes = list([x[1] for x in org_counts[1:] if x[0] != 'bacteria'])  # Counts as sizes for the pie chart\n",
    "\n",
    "# Create the pie chart\n",
    "plt.figure(figsize=(8, 8))  # Set the figure size\n",
    "plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=140)\n",
    "plt.title(\"Distribution of organisms\")\n",
    "plt.axis('equal')  \n",
    "# plt.savefig('ncbi_refseq_reference/organism_distribution.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e35c6c-9a68-4370-b950-ca13a401ed37",
   "metadata": {},
   "outputs": [],
   "source": [
    "org_counts = meta['new_group'].value_counts().reset_index().values\n",
    "labels = [f\"{label} ({count})\" for label, count in org_counts[:]] # Add counts to labels\n",
    "sizes = list([x[1] for x in org_counts[:]])  # Counts as sizes for the pie chart\n",
    "\n",
    "# Create the pie chart\n",
    "plt.figure(figsize=(8, 8))  # Set the figure size\n",
    "plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=140)\n",
    "plt.title(\"Distribution of organisms\")\n",
    "plt.axis('equal')  \n",
    "# plt.savefig('ncbi_refseq_reference/organism_distribution_with_bac.png', dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
